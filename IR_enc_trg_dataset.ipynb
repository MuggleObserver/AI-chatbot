{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "TRG_TRAIN_DATA = \"index20wtrain.resp\"  # 答案输入语言\n",
    "ENC_TRG_DATASET = \"enc_trg_dataset.txt\"\n",
    "CHECKPOINT_PATH = \"./IR_ckpt-5200\"\n",
    "TRG_TRAIN_DATA_SIZE = 200000\n",
    "\n",
    "\n",
    "HIDDEN_SIZE = 300           # LSTM的隐藏层规模\n",
    "NUM_LAYERS = 2              # 深层循环神经网络中的LSTM结构的层数\n",
    "VOCAB_SIZE = 10000          # 词汇表的大小（词汇表按照词频，由高到低向下排列）\n",
    "MAX_LEN = 50                # 限定句子的最大单词数量。\n",
    "BATCH_SIZE = 1              # 训练数据batch的大小\n",
    "\n",
    "def MakeDataset(file_path):\n",
    "    dataset = tf.data.TextLineDataset(file_path)\n",
    "    # 根据空格将单词编号切分开并放入一个一维向量。\n",
    "    dataset = dataset.map(lambda string: tf.string_split([string]).values)\n",
    "    # 将字符串形式的单词编号转化为整数。\n",
    "    dataset = dataset.map(\n",
    "        lambda string: tf.string_to_number(string, tf.int32))\n",
    "    # 统计每个句子的单词数量，并与句子内容一起放入Dataset中。\n",
    "    dataset = dataset.map(lambda x: (x, tf.size(x)))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def MakeTrgDataset(trg_path, batch_size):\n",
    "    # 统计src_path所含的总行数（src_path与trg_path所含行数相等）\n",
    "    trg_data = MakeDataset(trg_path)\n",
    "    # 规定填充后输出的数据维度。\n",
    "    padded_shapes = (\n",
    "        (tf.TensorShape([None]),  # 源句子是长度未知的向量\n",
    "         tf.TensorShape([])))  # 标签是单个数字\n",
    "    # 调用padded_batch方法进行batching操作。\n",
    "    batched_dataset = trg_data.padded_batch(batch_size, padded_shapes)\n",
    "    return batched_dataset\n",
    "\n",
    "# 定义IRModel类来描述模型\n",
    "class IRModel(object):\n",
    "    # 在模型的初始化函数中定义模型要用到的变量\n",
    "    def __init__(self):\n",
    "        # 定义编码器的LSTM结构\n",
    "        self.enc_cell = tf.nn.rnn_cell.MultiRNNCell(\n",
    "        [tf.nn.rnn_cell.BasicLSTMCell(HIDDEN_SIZE)\n",
    "         for _ in range(NUM_LAYERS)])\n",
    "\n",
    "        # 为源语言和目标语言分别定义词向量\n",
    "        self.embedding = tf.get_variable(\"src_emb\", [VOCAB_SIZE, HIDDEN_SIZE])\n",
    "        self.W = tf.get_variable(\"weights\", [HIDDEN_SIZE, HIDDEN_SIZE],\n",
    "                                 initializer=tf.truncated_normal_initializer())\n",
    "\n",
    "    # trg_input,trg_size,targets分别是上面MakeSrcTrgDataset函数产生的五种张量。\n",
    "    def create_enc_trg(self, trg_input, trg_size):\n",
    "\n",
    "        trg_emb = tf.nn.embedding_lookup(self.embedding, trg_input)\n",
    "\n",
    "        # 使用dynamic_rnn构造编码器。\n",
    "        with tf.variable_scope(\"encoder\"):\n",
    "            enc_trg_outputs, enc_trg_state = tf.nn.dynamic_rnn(self.enc_cell, trg_emb, sequence_length=trg_size,\n",
    "                                                               dtype=tf.float32)\n",
    "            # 因为编码器是一个双层LSTM，因此enc_state是一个包含两个LSTMStateTuple类的tuple，enc_state存储的是每一层的最后一个step的输出\n",
    "            # trg_enc_output的shape为BATCH_SIZE * HIDDEN_SIZE\n",
    "            trg_enc_output = enc_trg_outputs[:, -1, :]\n",
    "\n",
    "        return trg_enc_output\n",
    "\n",
    "\n",
    "def main():\n",
    "    with tf.variable_scope(\"IRModel\", reuse=None):\n",
    "        model = IRModel()\n",
    "    # 定义输入数据。\n",
    "    data = MakeTrgDataset(TRG_TRAIN_DATA,  BATCH_SIZE)\n",
    "    iterator = data.make_initializable_iterator()\n",
    "\n",
    "    (trg_input, trg_size) = iterator.get_next()\n",
    "    # 定义前向计算图。输入数据以张量形式提供给forward函数。\n",
    "    trg_output = model.create_enc_trg(trg_input, trg_size)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, CHECKPOINT_PATH)\n",
    "    sess.run(iterator.initializer)\n",
    "    def matrixAppend(sess, row, col):\n",
    "        outputs = np.zeros(shape=(row, col))\n",
    "        for num in range(row):\n",
    "            output = sess.run(trg_output)\n",
    "            outputs[num] = output[0]\n",
    "        return outputs\n",
    "\n",
    "    dataset = matrixAppend(sess, TRG_TRAIN_DATA_SIZE, HIDDEN_SIZE)\n",
    "    np.savetxt(ENC_TRG_DATASET, dataset)\n",
    "    sess.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
